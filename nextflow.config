/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core/metassembly Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')

// Global default params, used in configs
params {

    // TODO nf-core: Specify your pipeline's command line flags
    // Input Output options
    input                       = null
    outdir                      = null
    Account                     = "NO12345"
    mode                        = 0
    pipeline_prefix             = "MetaflowX"
    function                    = "mag"
    single_end                  = false
    remove_temp_sam_bam         = false
    pipeline_assets             = "${baseDir}"
    webhookurl                  = null


    // QC options
    skip_qc                     = false
    qc_tool                     = "fastp"
    adapters                    = "${params.pipeline_assets}/assets/TruSeq3-PE.fa"
    fastp_options               = "--cut_front --cut_front_window_size 1 --cut_front_mean_quality 5 --cut_tail --cut_tail_window_size 1  --cut_tail_mean_quality 5 --cut_right --cut_right_mean_quality 15 --length_required 50 --detect_adapter_for_pe"

    trim_ILLUMINACLIP_options   = "2:30:10"
    trim_options                = "LEADING:5 TRAILING:5 SLIDINGWINDOW:4:15 MINLEN:75 -phred33"
    qc_bowtie2_options          = "--very-sensitive --no-head --no-sq --reorder"
    host_db                     = "/share/database/Homo_sapiens/hg38_bowtie2_index" 
    host_db_index               = "hg38.index"

    phix_db                     = "/aimigene/lianglifeng/1.DataBase/Phix/phix_bowtie2_index" 
    phix_db_index               = "GCA_002596845.1_ASM259684v1_genomic.index"

    // Assembly options
    assembly_tool               = "metaspades"
    min_contig_len              = 2000
    metaspades_options          = "--meta"
    spades4downstream_analysis  = 'scaffolds'
    megahit_options             = "--min-contig-len ${params.min_contig_len}"
    metaquast_options           = "--rna-finding --max-ref-number 0"

    // contig taxonomy 
    contig_taxonomy             = false
    kraken2_contig              = false
    kraken2_contig_anno_options = null
    contig_taxonomy_output      = null

    cat_contig                  = true
    cat_contig_options          = null
    cat_gtdb_db                 = "/share/database/CAT_pack/GTDB/release226/"
    cat_pack                    =  "/share/app/CAT_pack/CAT_pack/"



    // Marker options
    skip_marker                 = false
    metaphlan                   = true
    metaphlan_version           = "4.0"
    mpa_db                      = "/share/database/metaphlan/mpa_vJan21"
    mpa_index                   = "mpa_vJan21_CHOCOPhlAnSGB_202103"
    sgb2gtdb_index              = "mpa_vJan21_CHOCOPhlAnSGB_202103_SGB"
    mpa_options                 = "--input_type fastq --read_min_len 50 --add_viruses -t rel_ab"
    mpa_extra_abun_method       = null
    save_metaphlan_output       = true
   
    humann                      = true
    humann_version              = "3"
    humann_chocophlan_db        = "/share/database/humann/v201901b/chocophlan"
    humann_protein_db           = "/share/database/humann/v201901b/uniprot/uniref_annotated/uniref90"
    humann_map_db               = "/share/database/humann/v201901b/full_mapping"
    humann_search_mode          = "uniref90"
    humann_options              = "--remove-temp-output --remove-column-description-output"
    humann_regroup_table_options= "-e 14"
    humann_map_CARD             = null
    humann_map_CAZy             = null
    humann_map_VFDB             = null
    humann_map_GMMs             = null
    ko_module                   = null
    ko_pathway                  = null
    save_humann_output          = true

    kraken2                     = false
    kraken2_db                  = "/share/database/Kraken2/standard"
    kraken2_options             = null
    bracken_options             = "-r 150 -t 1 "
    save_kraken2_output         = true
    

    // Geneset options
    prodigal_options            = "-p meta"
    prodigal_output             = null
    
    geneset_construction        = true
    gene_min_length             = 150
    cdhit_options               = "-c 0.95 -aS 0.9 -n 10 -M 0 -d 0"
    cdhit_split_run_eachthread  = 16
    cdhit_split_run_threshold   = 1000000
    cdhit_geneset_chunk_size    = 500000

    gene_function               = true
    eggnog_diamond_db           = "/share/app/SOP/nf-core/database/metagenome/eggnog_5.0/bact_arch/bact_arch.dmnd"
    eggnog_mapper_db            = "/share/database/eggnog/emapperdb-5.0.2"
    eggnog_options              = "--itype proteins -m diamond"
    eggnog_protein_chunk_size   = 10000
    
    gene_abundance_calculation   = true
    geneset_profile_bowtie2_options = null
    save_geneset_abundance      = true

    VFDB_db                     = null
    
    CARD_db                     = null
    rgi_load_options            = "--debug --kmer_size 61"
    rgi_main_options            = "--input_type protein --alignment_tool DIAMOND --clean --include_nudge"

    bigspace_path               = "/share/app/BiG-SCAPE"
    bigspace_db                 = null
    antismash_options           = "--genefinding-tool prodigal-m --minlength ${params.min_contig_len}"
    bigmap_family_options       = null 
    bigmap_map_options          = null

    ntDB_name                   = "ntDB"
    ntDB_bowtie2_options        = "--sensitive"
    nucleotide_db               = null

    proDB_name                  = "proDB"
    proDB_diamond_options       = "-e 1e-5 --id 40"
    protein_db                  = null


    // Binning options
    skip_binning                = false
    metabat2                    = false
    metabat2_options            = "--seed 1"
    concoct                     = true
    concoct_options             = null
    semibin2                    = true
    semibin2_options            = "--orf-finder prodigal --tmpdir tmp/ --environment global -m ${params.min_contig_len} --compression none"
    maxbin2                     = false
    maxbin2_options             = null
    metabinner                  = false
    metabinner_path             = "/share/app/miniconda3/envs/mymetabinner/bin"
    metabinner_options          = null
    binny                       = false
    binny_path                  = "/share/app/binny"
    binny_options               = null
    comebin                     = false
    comebin_options             = null
    vamb                        = false
    vamb_options                = " -m ${params.min_contig_len} --minfasta 10000 "
    metadecoder                 = true
    metadecoder_options         = " --min_sequence_length ${params.min_contig_len}  "


    binning_bowtie2_options     = null
    dastool_options             = "--write_bin_evals --write_bins"

    taxvamb                     = false
    taxvamb_options             = " -m ${params.min_contig_len} --minfasta 10000 "

    magscot_folder              = "/aimigene/lianglifeng/0.software/MAGScoT_workflow/MAGScoT/"
    magscot_options             = null


    checkm2_db                  = "/share/database/CheckM2/uniref100.KO.1.dmnd"
    checkm2_options             = "-x fa"
    completeness                = 50
    contamination               = 10
    QS                          = 40
    drep_split_run_threshold    = 800
    drep_bin_chunk_size         = 200
    drep_split_thread           = null  
    drep_split_mem              = null
    drep_options                = "-sa 0.95 -nc 0.3 --ignoreGenomeQuality"

    galah_options               = "--min-completeness ${params.completeness}  --max-contamination ${params.contamination} "


    ScoreBasedOptimizer         = true
    PermutationBinOptimizer     = true
    ContigTaxonomyOptimizer     = false

    binner_integrator           = "dastool"
    
    similarity_ratio            = 0.8
    
    rawbin_info                 = null
    HQ_unique_bins              = null

    bin_taxonomy                = true
    gtdbtk_db                   = "/share/database/gtdbtk/release214"
    mash_db                     = "/share/database/gtdbtk/release214/mash"
    gtdb_archaeal_metadata      = "/share/app/SOP/nf-core/database/metagenome/gtdbtk_R214/metadata/ar53_metadata_r214.tsv.gz"
    gtdb_bacterial_metadata     = "/share/app/SOP/nf-core/database/metagenome/gtdbtk_R214/metadata/bac120_metadata_r214.tsv.gz"
    gtdbtk_classify_wf_options  = "--extension fa --pplacer_cpus 1 --scratch_dir ./"
    gtdbtk_identify_options     = "--extension fa"
    gtdbtk_align_options        = null
    gtdbtk_infer_options        = null
    gtdb_bin_chunk_size         = 500

    bin_function                = true
    gene_info                   = null
    cdhit_clstr                 = null
    emapper_annotation          = null
    vfdb_annotation             = null
    card_annotation             = null
    cog_db_category             = "${params.pipeline_assets}/db/cog_level.txt"
    go_db_category              = "${params.pipeline_assets}/db/GO_ontology.txt"
    kegg_db_category            = "${params.pipeline_assets}/db/ko_category.txt"
    cazy_db_category            = "${params.pipeline_assets}/db/cazy_category.txt"

    bin_abundance_calculation   = true
    binset_profile_bowtie2_options = null
    coverm_options              = "-x fa --min-covered-fraction 0"
    method4coverm               = "relative_abundance,trimmed_mean,count"


    // refine & reassembly Bin options
    bin_refine                  = false
    genome_paths                = "/share/database/gtdbtk/release214/fastani/genome_paths.tsv"
    refine_bin_options          = "-a 50 -A 90 -b 1 -B 10"
    deepurify_db                = "/share/database/Deepurify2/Deepurify-DB/"
    deepurify_module            = "clean"
    deepurify_clean_options     = "--bin_suffix fa --gpu_num 0 --each_gpu_threads 1 --temp_output_folder ./tmp/"
    deepurify_rebin_options     = "--gpu_num 0 --each_gpu_threads 1 --temp_output_folder ./tmp/"
    cobra_options               = "-mink 21 -maxk 127 -lm 3"
    max_dist_threshold          = 0.2
    min_quality_score           = 50
    preprocess_bin_assembly_options = "--use_single_sample --max_dist_threshold ${params.max_dist_threshold}"

    bin_reassembly              = false
    reassembly_min_contig_len   = 2000
    reassembly_HQ_options       = "--completeness 90 --contamination 5"
    get_bin_assembly_options    = "--minCompleteness 90 --minContamination 5 --minQS 65 --minCount 10000 --minDepth 1"
    extract_bin_reads_options   = "--max_dist_threshold 0.2 --topSampleNum 10"
    bin_min_abundance           = 0.0001
    bin_min_popularity          = 0.001
    remove_samples              = null
    hybridSPAdes_options        = "--meta --only-assembler"


    // minitools
    //bra
    bin_QS_taxonomy             = null
    bins_count_abun             = null
    bins_mean_abun              = null
    bin_genome_floder           = null
    //bbs
    contig2bin                  = null
    protein_list                = null
    contig_list                 = null

    //svflow
    stat                        = false
    path_map                    = "${params.pipeline_assets}/assets/svflow/path_map.csv"
    profile_template            = "${params.pipeline_assets}/assets/svflow/profile_template.csv"

    //report
    report_topic                = "${params.pipeline_assets}/assets/report/topic.txt"
    report_order                = "${params.pipeline_assets}/assets/report/report.order.txt"
    report_template             = "${params.pipeline_assets}/assets/report/template_V20240307.html"
    report_images               = "${params.pipeline_assets}/assets/report/img"

    // Boilerplate options
    publish_dir_mode           = 'copy'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    hook_url                   = null
    help                       = false
    version                    = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'genomes'


    // Config options
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_description = null
    config_profile_contact     = null
    config_profile_url         = null
    config_profile_name        = null


    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '126.GB'
    max_cpus                   = 32
    max_time                   = '240.h'

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core/metassembly custom profiles from different institutions.
// Warning: Uncomment only if a pipeline-specific instititutional config already exists on nf-core/configs!
// try {
//   includeConfig "${params.custom_config_base}/pipeline/metassembly.config"
// } catch (Exception e) {
//   System.err.println("WARNING: Could not load nf-core/config/metassembly profiles: ${params.custom_config_base}/pipeline/metassembly.config")
// }


profiles {
    debug { 
        //process.beforeScript = 'echo $HOSTNAME' 
        conda.enabled          = true
        process.executor       = 'slurm'
        process.queue          = 'data'
        process.clusterOptions = "--account ${params.Account} -e slurm_%j.e -o slurm_%j.o"
        process.conda          = "/share/app/miniconda3/envs/metaflowX"
        //cleanup                = true
        params.config_profile_name = 'data'
        //workDir                = "/aimigene/NF/${params.Account}"
    }

    standard {
        conda.enabled          = true
        process.conda          = "/share/app/miniconda3/envs/metaflowX"
        //cleanup                = true
        //workDir                = "/aimigene/NF/${params.Account}"
    }

    local {
        conda.enabled          = true
        process.conda          = "/share/app/miniconda3/envs/metaflowX"
        params.webhookurl      = "https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=610cfdbb-4b18-4cac-ac26-3b9bf80f6a3e"
        //cleanup                = true
        //workDir                = "/aimigene/NF/${params.Account}"
    }

    slurm {
        conda.enabled          = true
        process.executor       = 'slurm'
        process.queue          = 'md'
        process.clusterOptions = "--account ${params.Account} -e slurm_%j.e -o slurm_%j.o"
        process.conda          = "/share/app/miniconda3/envs/metaflowX"
        //cleanup                = true
        params.config_profile_name = 'slurm'
        params.webhookurl      = "https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=610cfdbb-4b18-4cac-ac26-3b9bf80f6a3e"
        //workDir                = "/aimigene/NF/${params.Account}"
    }

    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
    test_mpa4 { includeConfig 'conf/test_mpa4.config' }
    test_all  { includeConfig 'conf/test_all.config'  }
}


// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'nf-core/MetaflowX'
    author          = """YangYing"""
    homePage        = 'https://github.com/nf-core/MetaflowX'
    description     = """this is a pipleline for metagenomics assembly"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=22.10.1'
    version         = '1.0dev'
    doi             = ''
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
